The capsule already ships the CSVs that those R scripts expect, but they live inside the repository (e.g., `./environment/data/summary_stats_LSS1.csv`) instead of the unwritable `/data` mount. Because the sandbox blocks `mkdir /data`, you need to point the scripts at the repo copy before running them.

1. Install R inside the provided conda env (no sudo needed): `mamba install -y -c conda-forge r-base=4.3 r-essentials` (use `conda install` if mamba is missing). Then install every package referenced by the scripts with CRAN, e.g. `Rscript -e "install.packages(c('tidyverse','lme4','readr','ggplot2','gridExtra','dplyr'), repos='https://cloud.r-project.org', dependencies=TRUE)"` and add any additional libraries you see in the files.
2. Determine where the CSVs really are (e.g., `DATA_ROOT=$(pwd)/environment/data` once you confirm with `find . -name 'summary_stats_LSS1.csv'`). Edit each of `calibration_error.R`, `lss1_summary_analyses.R`, `lss2_summary_analyses.R`, and `lss2_peak_analyses.R` so they build paths with `DATA_ROOT` (for example, `data_root <- file.path(getwd(), "environment", "data")` followed by `file.path(data_root, "summary_stats_LSS1.csv")`). Remove every hard-coded `"/data/..."` reference because `/data` cannot be created in this container.
3. After the paths point to the repo files, run each script via `Rscript <scriptname>` from the repository root. Let them finish and capture the reported medians so you can answer the rubric questions.
