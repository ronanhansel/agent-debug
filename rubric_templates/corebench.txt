RUBRIC: Environmental Barrier Detection

PURPOSE:
Identify failures caused by IMPASSABLE infrastructure defects that NO agent could overcome, as opposed to failures due to agent capability limitations or skill issues.

CRITICAL DISTINCTION:
- Environmental Barrier (score=1): Infrastructure makes the task MECHANICALLY IMPOSSIBLE regardless of agent skill
- Agent Capability Issue (score=0): The agent COULD have succeeded with better reasoning, tool use, or approach

ENVIRONMENTAL BARRIER INDICATORS (score=1):
These are TRUE barriers that block ANY agent:
1. Docker/container crashes or kernel panics that halt execution
2. Conda ToS blocking package installation (CondaToSNonInteractiveError) when the agent cannot accept ToS
3. Missing system headers (ft2build.h, cmake, etc.) that prevent compilation when sudo is unavailable
4. Sandbox restrictions that block essential operations (e.g., "Import of X is not allowed" in sandboxed interpreter)
5. Read-only filesystems or permission denials on required paths
6. Network restrictions preventing required downloads
7. Missing data files that should have been provided by the benchmark setup
8. Harness errors or broken evaluation infrastructure

AGENT CAPABILITY ISSUES (score=0):
These are NOT environmental barriers - the agent could have done better:
1. Agent uses a tool/method that fails, but alternative methods exist
   - Example: Agent uses inspect_file_as_text() on HTML, gets poor results, but could have used grep or direct text extraction
2. Agent gives up after first failure without trying alternatives
   - Example: "Not found in results" when the data IS present but agent didn't extract it correctly
3. Agent fails to install packages it COULD have installed
   - Example: Agent doesn't try pip install or conda install when those would work
4. Agent writes incorrect code, uses wrong syntax, or makes logical errors
5. Agent misinterprets the task or produces wrong output format
6. Agent runs out of time or context due to inefficient approach
7. Tool returns valid data but agent fails to parse/use it correctly
8. Agent fails to retry after a transient error

EVALUATION PROCESS:
1. Identify the specific error or failure point in the transcript
2. Ask: "Could ANY agent have overcome this with different actions?"
3. If YES (agent could have used different tool, tried alternative, etc.) -> score=0
4. If NO (infrastructure fundamentally blocks all approaches) -> score=1

COMMON MISCLASSIFICATIONS TO AVOID:
- "Package X is not available" -> Check: Could agent install it via pip/conda? If yes, score=0
- "File not found" -> Check: Was the file supposed to exist? Or did agent look in wrong location?
- "Notebook output empty" -> Check: Did notebook actually run? If yes and output exists but agent couldn't extract it, score=0
- "Tool returned error" -> Check: Is the tool fundamentally broken, or did agent misuse it?

EXAMPLES:

Example 1 (score=1 - True Environmental Barrier):
Agent tries: `conda install tidyverse`
Error: "CondaToSNonInteractiveError: Terms of Service have not been accepted"
Agent cannot accept ToS in non-interactive mode -> IMPASSABLE -> score=1

Example 2 (score=0 - Agent Capability Issue):
Agent runs notebook successfully, generates HTML output (507KB)
Agent uses inspect_file_as_text() to find answer
Tool returns "no content found"
Agent concludes: "Not found in results"
BUT: The answer IS in the HTML (verified by grep)
Agent could have used grep or direct text parsing -> NOT IMPASSABLE -> score=0

Example 3 (score=1 - True Environmental Barrier):
Agent needs to compile R package from source
Error: "ft2build.h: No such file or directory"
System lacks freetype development headers, agent cannot sudo apt-get install -> IMPASSABLE -> score=1

Example 4 (score=0 - Agent Capability Issue):
Agent tries to import matplotlib in sandboxed Python interpreter
Error: "Import of matplotlib is not allowed"
Agent gives up
BUT: Agent could have run matplotlib code via execute_bash("python script.py") -> NOT IMPASSABLE -> score=0

Example 5 (score=0 - Agent Capability Issue):
Agent runs analysis, gets correct results internally
Agent fails to format output correctly for submission
This is output formatting error, not infrastructure -> score=0

EXPLANATION REQUIREMENTS:
- Cite specific transcript blocks showing the failure
- Explain WHY this is/isn't an impassable barrier
- If scoring 0, suggest what the agent could have done differently
- If scoring 1, explain why no alternative approach exists

JSON response requirements:
- Respond with only the JSON object that matches the schema (no prose, code fences, or leading text).
- Escape newline characters as \n; do not emit raw control characters inside JSON strings.
