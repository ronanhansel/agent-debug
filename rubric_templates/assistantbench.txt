# AssistantBench Intrinsic Formation Error Detection Rubric

## Purpose
This rubric evaluates whether a task failure on the AssistantBench benchmark stems from an **Intrinsic Formation Error (IFE)** in the benchmark itself, rather than agent capability limitations.

## Scoring
- **Score 1**: An intrinsic benchmark defect exists AND caused the failure (no agent could succeed)
- **Score 0**: The failure is due to agent capability issues (a better agent could have succeeded)

## Two-Question Framework

### Question 1: Does an Intrinsic Formation Defect Exist?
Analyze whether the benchmark item contains any of the deficiency categories below.

### Question 2: Did the Defect Cause This Failure?
Even if a defect exists, determine whether it actually prevented success, or whether the agent failed for other reasons.

---

## Deficiency Categories for AssistantBench

### 1. Website Accessibility Issues
The target website cannot be accessed or navigated:
- Website is permanently offline or domain expired
- Website requires authentication that cannot be bypassed
- Website blocks automated browsers (CAPTCHA, bot detection)
- Geographic restrictions prevent access
- Website has changed structure since task creation

### 2. Answer Validity Problems
The expected answer is incorrect or outdated:
- Information has changed since task creation (prices, dates, facts)
- Multiple valid answers exist but only one is accepted
- Expected answer format is ambiguous or inconsistent
- Gold answer contains factual errors

### 3. Task Specification Ambiguity
The task description lacks necessary information:
- Query is ambiguous with multiple valid interpretations
- Required navigation path is not determinable from description
- Task references entities that no longer exist
- Temporal context is missing (as of when?)

### 4. Evaluation Metric Defects
The scoring system has problems:
- Partial credit not given for partially correct answers
- String matching is too strict (case, formatting)
- Numerical tolerance is inappropriate
- List ordering requirements are unclear

### 5. Browser Environment Limitations
The browser automation environment is inadequate:
- JavaScript rendering fails for required content
- Iframes or shadow DOM not properly handled
- Cookie/session management breaks navigation
- Network timeouts for slow-loading sites

### 6. Data Freshness Issues
The benchmark data is stale:
- Websites have been redesigned
- Products or services no longer exist
- Pricing or availability has changed
- Company information is outdated

---

## CRITICAL EXCLUSIONS: Agent Capability Issues (Score 0)

Do NOT classify the following as benchmark deficiencies:

### 1. Navigation Failures
- Agent clicks wrong elements
- Agent fails to scroll to find content
- Agent navigates to wrong website or page
- Agent fails to wait for page to load
- These are agent navigation issues, not benchmark defects

### 2. Information Extraction Errors
- Agent extracts wrong data from correct page
- Agent misreads or misinterprets content
- Agent fails to aggregate information correctly
- Agent produces wrong format for answer

### 3. Search Strategy Issues
- Agent uses inefficient search queries
- Agent fails to find information that exists
- Agent gives up too early
- Agent does not try alternative approaches

### 4. Tool Misuse
- Agent misuses browser actions
- Agent fails to handle popups or dialogs
- Agent does not wait for dynamic content
- Agent breaks navigation with back/forward

### 5. Reasoning Errors
- Agent makes calculation mistakes
- Agent draws wrong conclusions from data
- Agent fails to combine information from multiple sources
- Agent misunderstands the question

---

## Evidence Requirements

For Score 1, you MUST provide:
1. **Specific defect identification**: Show the exact benchmark issue
2. **Impossibility proof**: Demonstrate why NO agent could succeed
3. **Current state verification**: Confirm the issue persists

For Score 0, explain:
1. What the agent did wrong
2. What a capable agent could have done instead
3. Why the information was retrievable

---

## Response Format

Respond with a JSON object:

```json
{
  "score": 0 or 1,
  "deficiency_exists": true/false,
  "deficiency_caused_failure": true/false,
  "deficiency_type": "category name or 'none'",
  "existence_reasoning": "analysis of whether a benchmark defect exists",
  "causation_reasoning": "analysis of whether the defect caused failure",
  "evidence": "specific quotes from transcript supporting conclusion"
}
```

---

## Common AssistantBench Failure Patterns

### Likely Agent Issues (Score 0):
- Agent navigated to wrong website
- Agent extracted price from wrong product
- Agent failed to scroll down to find answer
- Agent gave up after first search attempt failed
- Agent produced answer in wrong format (string vs number)

### Potential Benchmark Issues (Score 1):
- Website returns 404 or connection refused
- CAPTCHA blocks all automated access
- Product/entity in task no longer exists anywhere
- Gold answer is demonstrably incorrect
- Task requires information that was never public
